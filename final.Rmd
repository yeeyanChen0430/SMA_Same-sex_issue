---
title: '0605'
author: "Bolun Lin"
date: "2019年6月5日"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: style.css
---

### 系統設置
```{r}
Sys.setlocale("LC_CTYPE", "cht")
```


```{r message=FALSE, warning=FALSE, paged.print=FALSE, r,echo=FALSE}
pacman::p_load(dplyr, tidytext, stringr, wordcloud2,tidyverse,knitr,kableExtra,NLP, ggplot2,readr,data.table,reshape2,tidyr,scales,jiebaR,htmltools,ggraph, igraph, reshape2, widyr,gtools)



```

### 載入文章及留言
- 資料來源:
  - ptt八卦板 去年9月到2019/6/5 
  - 關鍵字：同性婚姻、同性戀、同性、同志、gay、lesbian、同婚、反同、甲甲、同性婚姻、LGBT
  - 分為文章以及留言
```{r}
comments = read.csv("./comments.csv") 
articles = read.csv("./articles.csv")
```
### 看一下資料
```{r}
head(comments)
head(articles)
str(comments)
str(articles)

table(nchar(comments$commentContent)>6)
```

### 過濾資料
```{r}
articles$sentence=as.character(articles$sentence)
comments$commentContent =as.character(comments$commentContent)
comments =comments%>%
  filter(nchar(comments$commentContent)>6)
data_count_by_date <- articles %>% 
  group_by(artDate) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

```


```{r}
plot_date <- 
  data_count_by_date %>% 
  ggplot(aes(x = as.Date(artDate), y = count)) +
  geom_line(size = 0.5) + 
  geom_vline(xintercept = as.numeric(as.Date("2019-02-15")), col='red') +
  scale_x_date(labels = date_format("%Y/%m/%d" )) +
  ggtitle("ptt八卦板 討論文章數") + 
  xlab("日期") + 
  ylab("數量") + 

  theme(text = element_text(family = "Heiti TC Light")) #加入中文字型設定，避免中文字顯示錯誤。

plot_date
```

- 2018/11 ：同婚專法公投
- 2018/02/20 ：同婚專法草案出爐
- 2018/03/23 ：柯文哲波士頓演講 自爆同婚投「反對票」
- 2018/05 ：同性專法通過

### 增加結巴字典以及正規化function已得到tokens
```{r}
jieba_tokenizer <- worker(user="dict/user_dict.txt", stop_word = "dict/stop_words.txt")
clean = function(txt) {
  txt = gsub("B\\w+", "", txt) #去除@或#後有數字,字母,底線 (標記人名或hashtag)
  txt = gsub("(http|https)://.*", "", txt) #去除網址
  txt = gsub("[ \t]{2,}", "", txt) #去除兩個以上空格或tab
  txt = gsub("\\n"," ",txt) #去除換行
  txt = gsub("\\s+"," ",txt) #去除一個或多個空格
  txt = gsub("^\\s+|\\s+$","",txt) #去除前後一個或多個空格
  txt = gsub("&.*;","",txt) #去除html特殊字元編碼
  txt = gsub("[a-zA-Z0-9?!. ']","",txt) #除了字母,數字 ?!. ,空白的都去掉
  txt }
tokenizer <- function(t) {
  lapply(t, function(x) {
    tokens <- segment(x, jieba_tokenizer)
    return(tokens)
  })
}
data_tokens <- articles %>% 
  unnest_tokens(word, sentence, token=tokenizer)
data_tokens$word = clean(data_tokens$word)
data_tokens = data_tokens %>%
  filter(!word == "")
```

### 計算詞彙的出現次數，如果詞彙只有一個字則不列入計算
```{r}
data_tokens_count <- data_tokens %>% 
  filter(nchar(.$word)>1) %>%
  group_by(word) %>% 
  summarise(sum = n()) %>% 
  filter(sum>1) %>%
  arrange(desc(sum))
# 印出最常見的20個詞彙
kable(head(data_tokens_count,20)) %>% 
  kable_styling(bootstrap_options = c("striped", "hover")) %>% 
  scroll_box(height = "300px")
```

### 文字雲
```{r}
data_tokens_count %>% wordcloud2()
```
